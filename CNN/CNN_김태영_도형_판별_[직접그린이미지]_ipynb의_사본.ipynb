{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CNN 모델 직접 구현\n",
        "###김태영\n",
        "https://tykimos.github.io/2017/03/08/CNN_Getting_Started/"
      ],
      "metadata": {
        "id": "VHJ2HtKr6tG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[순서] \n",
        "\n",
        "문제 정의하기 \n",
        "\n",
        "데이터 준비하기 \n",
        "\n",
        "데이터셋 생성하기 \n",
        "\n",
        "모델 구성하기 \n",
        "\n",
        "모델 학습과정 설정하기 \n",
        "\n",
        "모델 학습시키기 \n",
        "\n",
        "모델 평가하기 "
      ],
      "metadata": {
        "id": "2hwlT2lr601f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1 문제정의"
      ],
      "metadata": {
        "id": "cy_gd-tJ6-K2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMfyzYtS6sQk"
      },
      "outputs": [],
      "source": [
        "# 다중 클래스 분류\n",
        "# 입력 -> 손으로 그린 삼각형, 사각형, 원 이미지\n",
        "# 출력 -> 삼각형, 사각형, 원일 확률 나타내는 벡터\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 랜덤시드 고정시키기\n",
        "np.random.seed(3) #매 시행마다 결과 달라지지 않도록"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그림판 그림 \n",
        "\n",
        "http://tykimos.github.io/warehouse/2017-3-8_CNN_Getting_Started_handwriting_shape.zip"
      ],
      "metadata": {
        "id": "ytLKT_3F8Kee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2 데이터셋 생성"
      ],
      "metadata": {
        "id": "P1AjKoGL8Tqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스에서는 이미지 파일을 쉽게 학습시킬 수 있도록 ImageDataGenerator 클래스를 제공합니다. ImageDataGenerator 클래스는 데이터 증강 (data augmentation)을 위해 막강한 기능을 제공하는 데, 이 기능들은 다른 강좌에세 다루기로 하고, 본 강좌에서는 특정 폴더에 이미지를 분류 해놓았을 때 이를 학습시키기 위한 데이터셋으로 만들어주는 기능을 사용해보겠습니다.\n",
        "\n",
        "먼저 ImageDataGenerator 클래스를 이용하여 객체를 생성한 뒤 flow_from_directory() 함수를 호출하여 제네레이터(generator)를 생성합니다. flow_from_directory() 함수의 주요인자는 다음과 같습니다.\n",
        "\n",
        "첫번재 인자 : 이미지 경로를 지정합니다.\n",
        "target_size : 패치 이미지 크기를 지정합니다. 폴더에 있는 원본 이미지 크기가 다르더라도 target_size에 지정된 크기로 자동 조절됩니다.\n",
        "batch_size : 배치 크기를 지정합니다.\n",
        "class_mode : 분류 방식에 대해서 지정합니다.\n",
        "categorical : 2D one-hot 부호화된 라벨이 반환됩니다.\n",
        "binary : 1D 이진 라벨이 반환됩니다.\n",
        "sparse : 1D 정수 라벨이 반환됩니다.\n",
        "None : 라벨이 반환되지 않습니다.\n",
        "본 예제에서는 패치 이미지 크기를 24 x 24로 하였으니 target_size도 (24, 24)로 셋팅하였습니다. 훈련 데이터 수가 클래스당 15개이니 배치 크기를 3으로 지정하여 총 5번 배치를 수행하면 하나의 epoch가 수행될 수 있도록 하였습니다. 다중 클래스 문제이므로 class_mode는 ‘categorical’로 지정하였습니다. 그리고 제네레이터는 훈련용과 검증용으로 두 개를 만들었습니다."
      ],
      "metadata": {
        "id": "70McHkAs8Zi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "_fz7hN6u--ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_data = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_data.flow_from_directory(\n",
        "        '/content/gdrive/MyDrive/kaggle/handwriting_shape/train',\n",
        "        target_size=(24, 24),\n",
        "        batch_size=10,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_data = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_data.flow_from_directory(\n",
        "        '/content/gdrive/MyDrive/kaggle/handwriting_shape/test',\n",
        "        target_size=(24, 24),    \n",
        "        batch_size=10,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "uyAqyNLz7NmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Yf1zhSX6s9K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3 모델 구성"
      ],
      "metadata": {
        "id": "khM-LAPF8g97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "영상 분류에 높은 성능을 보이고 있는 컨볼루션 신경망 모델을 구성해보겠습니다. 각 레이어들은 이전 강좌에서 살펴보았으므로 크게 어려움없이 구성할 수 있습니다.\n",
        "\n",
        "컨볼루션 레이어 : 입력 이미지 크기 24 x 24, 입력 이미지 채널 3개, 필터 크기 3 x 3, 필터 수 32개, 활성화 함수 ‘relu’\n",
        "컨볼루션 레이어 : 필터 크기 3 x 3, 필터 수 64개, 활성화 함수 ‘relu’\n",
        "맥스풀링 레이어 : 풀 크기 2 x 2\n",
        "플래튼 레이어\n",
        "댄스 레이어 : 출력 뉴런 수 128개, 활성화 함수 ‘relu’\n",
        "댄스 레이어 : 출력 뉴런 수 3개, 활성화 함수 ‘softmax’"
      ],
      "metadata": {
        "id": "H3Y0-OPd8iwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(24,24,3)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "id": "quPzmIEg8gZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "sZ--RO6OtU0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "metadata": {
        "id": "5k2Zoo8s8mcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4 모델 학습과정 설정"
      ],
      "metadata": {
        "id": "ThTWNwR-_uCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델을 정의했다면 모델을 손실함수와 최적화 알고리즘으로 엮어봅니다.\n",
        "\n",
        "loss : 현재 가중치 세트를 평가하는 데 사용한 손실 함수 입니다. 다중 클래스 문제이므로 ‘categorical_crossentropy’으로 지정합니다.\n",
        "optimizer : 최적의 가중치를 검색하는 데 사용되는 최적화 알고리즘으로 효율적인 경사 하강법 알고리즘 중 하나인 ‘adam’을 사용합니다.\n",
        "metrics : 평가 척도를 나타내며 분류 문제에서는 일반적으로 ‘accuracy’으로 지정합니다."
      ],
      "metadata": {
        "id": "a_JujbfB__k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "meAOyD_f_sRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5 모델 학습시키기"
      ],
      "metadata": {
        "id": "-OJN8uGxADRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스에서는 모델을 학습시킬 때 주로 fit() 함수를 사용하지만 제네레이터로 생성된 배치로 학습시킬 경우에는 fit_generator() 함수를 사용합니다. 본 예제에서는 ImageDataGenerator라는 제네레이터로 이미지를 담고 있는 배치로 학습시키기 때문에 fit_generator() 함수를 사용하겠습니다.\n",
        "\n",
        "첫번째 인자 : 훈련데이터셋을 제공할 제네레이터를 지정합니다. 본 예제에서는 앞서 생성한 train_generator으로 지정합니다.\n",
        "steps_per_epoch : 한 epoch에 사용한 스텝 수를 지정합니다. 총 45개의 훈련 샘플이 있고 배치사이즈가 3이므로 15 스텝으로 지정합니다.\n",
        "epochs : 전체 훈련 데이터셋에 대해 학습 반복 횟수를 지정합니다. 100번을 반복적으로 학습시켜 보겠습니다.\n",
        "validation_data : 검증데이터셋을 제공할 제네레이터를 지정합니다. 본 예제에서는 앞서 생성한 validation_generator으로 지정합니다.\n",
        "validation_steps : 한 epoch 종료 시 마다 검증할 때 사용되는 검증 스텝 수를 지정합니다. 홍 15개의 검증 샘플이 있고 배치사이즈가 3이므로 5 스텝으로 지정합니다."
      ],
      "metadata": {
        "id": "7rCxGO_QAG-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=5,\n",
        "        epochs=100,\n",
        "        validation_data=test_generator,\n",
        "        validation_steps=5)"
      ],
      "metadata": {
        "id": "HKSv4m2AABhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6 모델 평가"
      ],
      "metadata": {
        "id": "L6804M8TAfHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습한 모델을 평가해봅니다. 제네레이터에서 제공되는 샘플로 평가할 때는 evaluate_generator 함수를 사용합니다."
      ],
      "metadata": {
        "id": "WXKSmihTAq6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-- Evaluate --\")\n",
        "scores = model.evaluate_generator(test_generator, steps=5)\n",
        "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "id": "ElLNV9dyANoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7 모델 사용"
      ],
      "metadata": {
        "id": "DwTeNzy3AwzL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 사용 시에 제네레이터에서 제공되는 샘플을 입력할 때는 predict_generator 함수를 사용합니다. 예측 결과는 클래스별 확률 벡터로 출력되며, 클래스에 해당하는 열을 알기 위해서는 제네레이터의 ‘class_indices’를 출력하면 해당 열의 클래스명을 알려줍니다."
      ],
      "metadata": {
        "id": "XNCt9T7CAyOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-- Predict --\")\n",
        "output = model.predict_generator(test_generator, steps=5)\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
        "print(test_generator.class_indices)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "8vNa1HzYAvMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#전체 코드"
      ],
      "metadata": {
        "id": "0ZAc__skBhs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU 연결 지속 코드 + F12에서\n",
        "\n",
        "function ClickConnect(){ \n",
        "console.log(\"Working\");  \n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()  \n",
        "} \n",
        "setInterval(ClickConnect,60000)\n"
      ],
      "metadata": {
        "id": "hUJZ4wc4hkGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "rvY4IjZgc04d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(24,24,3)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "cy6EQRJbwOtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "image_gen = ImageDataGenerator(rescale=(1/255.))\n",
        "\n",
        "train_gen = image_gen.flow_from_directory('/content/gdrive/MyDrive/kaggle/food_minidata/train',\n",
        "                                          batch_size = 32,\n",
        "                                          target_size = (224, 224,),\n",
        "                                          classes=['apple_pie', 'bibimbap'],\n",
        "                                          class_mode = 'binary',\n",
        "                                          seed = 2020)\n",
        "test_gen = image_gen.flow_from_directory('/content/gdrive/MyDrive/kaggle/food_minidata/test',\n",
        "                                          batch_size = 32,\n",
        "                                          target_size = (224, 224,),\n",
        "                                          classes=['apple_pie', 'bibimbap'],\n",
        "                                          class_mode = 'binary',\n",
        "                                          seed = 2020)\n",
        "\n",
        "class_labels = ['apple_pie', 'bibimbap']\n",
        "batch = next(train_gen)\n",
        "images, labels = batch[0], batch[1] # 0번 이미지데이터 1번 레이블\n",
        "print(labels[:10])\n",
        "plt.figure(figsize=(16,8))\n",
        "for i in range(32) :\n",
        "    ax = plt.subplot(4,8,i+1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.title(class_labels[labels[i].astype(np.int)])\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqySp9jS94cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. 사용할 패키지 불러오기\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 1. 데이터 생성하기\n",
        "img = [24,24,3]\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/gdrive/MyDrive/kaggle/food_1-1000/train300',\n",
        "        target_size=(24,24),\n",
        "        batch_size=10,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/gdrive/MyDrive/kaggle/food_1-1000/test300',\n",
        "        target_size=(24,24),    \n",
        "        batch_size=10,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# 상수 define -> 이미지 크기 조정\n",
        "\n",
        "# 2. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(img)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# # 저장한 모델 불러오기\n",
        "# from keras.models import load_model\n",
        "# model = load_model('/content/gdrive/MyDrive/my_model.h5')\n",
        "\n",
        "\n",
        "# 3. 모델 학습과정 설정하기\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# 4. 모델 학습시키기\n",
        "model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=63,\n",
        "        epochs=50,\n",
        "        validation_data=test_generator,\n",
        "        validation_steps=27)\n",
        "\n",
        "# 5. 모델 평가하기\n",
        "print(\"-- Evaluate --\")\n",
        "scores = model.evaluate_generator(test_generator, steps=5)\n",
        "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# 6. 모델 사용하기\n",
        "print(\"-- Predict --\")\n",
        "output = model.predict_generator(test_generator, steps=5)\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
        "print(test_generator.class_indices)\n",
        "print(output) \n",
        "print(test_generator.filenames,\"\\n\")\n",
        "\n",
        "# keras 모델 저장\n",
        "from keras.models import load_model\n",
        "model.save('/content/gdrive/MyDrive/my_model.h5')"
      ],
      "metadata": {
        "id": "JOoefWy9BjFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 작업중인 디렉토리 출력\n",
        "!pwd\n",
        "\n",
        "# 현재 작업하는 위치 변경\n",
        "%cd gdrive/'My Drive'\n",
        "\n",
        "# 파일 생성\n",
        "with open('/content/gdrive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')"
      ],
      "metadata": {
        "id": "EcNFqoylBvSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keras 모델 저장, 불러오기\n",
        "from keras.models import load_model\n",
        "model.save('my_model.h5')"
      ],
      "metadata": {
        "id": "rwe_yTCrCWVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/gdrive/MyDrive/my_model.h5')"
      ],
      "metadata": {
        "id": "thzOnnskCwER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/tutorials/keras/save_and_load.ipynb?hl=ko#scrollTo=SkGwf-50zLNn \n",
        "\n",
        "딥러닝 모델 저장 및 불러오기"
      ],
      "metadata": {
        "id": "TcThvTBNXPXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 모델 구조를 확인합니다\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "caSoz5wCSYYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 복원된 모델을 평가합니다\n",
        "loss, acc = model.evaluate(test_generator, verbose=2)\n",
        "print('복원된 모델의 정확도: {:5.2f}%'.format(100*acc))\n",
        "\n",
        "print(model.predict(test_generator).shape)"
      ],
      "metadata": {
        "id": "oiubRpwHSq2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 파일 사진 크기 변경\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "files = glob.glob('/content/gdrive/MyDrive/kaggle/food_minidata/test/*.jpg')\n",
        "\n",
        "for f in files:\n",
        "    img = Image.open(f)\n",
        "    img_resize = img.resize((int(24), int(24)))\n",
        "    title, ext = os.path.splitext(f)\n",
        "    img_resize.save(title + '_half' + ext)"
      ],
      "metadata": {
        "id": "BEm8A-R2IFqT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}