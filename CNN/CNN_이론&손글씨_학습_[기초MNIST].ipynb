{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Si93M57jJss"
      },
      "outputs": [],
      "source": [
        "#딥러닝 - CNN(컨볼루셔널 뉴럴 네크워크)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[이론]\n",
        "다층 퍼셉트론 -> 단점  \n",
        "1. 1차원으로 해석하기 때문에, 2차원 평면의 지역정보 잃음\n",
        "2. 픽셀 하나의 변화에도 민감\n",
        "3. 모델 크기 커야하고 학습 시간 오래걸리며 과대적합 가능성 높음\n",
        "##CNN ->  \n",
        "* 2차원 배열 그대로인 상태에서, 생김새 정보를 학습함  \n",
        "* 필터(커널) :: (n*n행렬형태,대각선에 255,나머지에 0값)  \n",
        "필터가 이동하며 생김새 정보 얻음  \n",
        "이동기법 = 스트라이드  \n",
        "필터와 겹치는 이미지 부분 = 수용영역  \n",
        "* 필터가 이미지와 겹칠때 이미지 값과 필터 픽셀값을 곱한 합 -> 값이 크면 겹치는 부분 많다, 값이 작으면 겹치는 부분 적다\n"
      ],
      "metadata": {
        "id": "xbPR5BHNjhmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 방식 :: 2*2필터, 5*5이미지 가정 -> 최종 행렬은 4*4형태로 나옴\n",
        "* 풀링 레이어 :: 모델 파라미터를 줄임 -> 계산량 줄임, 과대적합 조절가능, 맥스풀링 -> 4*4형태를 2*2로 만들수 있음(2*2행렬의 가장 큰값을 가져옴)\n",
        "* 제로 패딩 :: 0으로 이미지(입력행렬)을 감쌈 -> n+1*n+1 행렬이 됨 -> 필터를 3*3행렬로 늘리면, -> 전과같은 n+1*n+1행렬의 결과가 나옴\n",
        "* 컬러 이미지 분류 :: ex) (10,28,28,3) 이면 이미지 개수10개, 28픽셀(가로세로), 색상 3가지라고 해석, 겹치는 레이어의 개수 = 깊이 (하나의CONV에 N개의 필터가 있다면, 깊이는 N이다)\n"
      ],
      "metadata": {
        "id": "hfaYqddtnFKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CNN 모델 학습 이해\n",
        "1. 입력 레이어에 3가지(빨강,초록,파랑) 이미지가 들어가면 깊이는 3, (5,5,3), 5*5행렬\n",
        "2. 첫번째 CONV1에는 4개의 필터 존재, 출력값으로 4개의 피처맵이 출력 (피처맵은 필터가 스트라이드를 거쳐 만든 결과 행렬), 4*4행렬 4개 (4,4,4)\n",
        "3. CONV2에서는 총 3개의 필터 존재, 3개의 피처맵 출력, 4*4행렬 3개 (4,4,3)\n",
        "4. 풀링 레이어에서 피처맵 크기 절반으로 줄임, 2*2행렬 3개 (2,2,3)\n",
        "5. 모든 값을 일렬로 정렬, 2*2*3=12 배열 (12,1)\n",
        "6. 이 12개 값은 CONV로 획득된 특징임 -> FC에 연결하여 0-9까지 값을 상징하는 10개의 노드로 값을 전달 -> softmax로 확률 출력 -> 옵티마이저로 역전파 이용해 파라미터 최적화\n",
        "\n",
        "* 실습자는 필터의 개수와 형태만 결정 <-> 필터의 역할은 최적화 과정을 통해 모델 스스로 부여"
      ],
      "metadata": {
        "id": "PdSdyIMqnr2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN[실습] :: 손글씨 학습 및 테스트\n",
        "텐서플로로 MNIST 숫자 데이터 분류"
      ],
      "metadata": {
        "id": "Y_jyaCvxpYIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(url= \"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/practice_cnn.png\", width=800, height=200)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "-8j-T0dEpcKF",
        "outputId": "e872c236-7821-496f-aa2d-ea968980422d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/practice_cnn.png\" width=\"800\" height=\"200\"/>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# 항상 같은 결과를 갖기 위해 랜덤 시드 설정\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "#라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "JXotcvuwp21w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40bf4f7d-551d-4a67-f8ba-bc857486ef86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "ifnWp5fGoqUK",
        "outputId": "79e0d653-057f-498f-f240-90ac8bde17a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3737b1dc60a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 120\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 획득\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA9XOTtUqFF4",
        "outputId": "521c60c3-45b2-4009-fe4b-977ce4e9d8f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0-255까지 그레이스케일 확인\n",
        "print(x_train[0][8])\n",
        "print(y_train[0:9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG5mjUaIqJBV",
        "outputId": "1f60f561-86fe-45e9-998f-2a44ae0cf3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "[5 0 4 1 9 2 1 3 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10000개의 샘플, 28*28이미지\n",
        "print(\"test data has \" + str(x_test.shape[0]) + \" samples\")\n",
        "print(\"every test data is \" + str(x_test.shape[1]) \n",
        "      + \" * \" + str(x_test.shape[2]) + \" image\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSesOUzkqTat",
        "outputId": "eb0c03c6-ff14-4388-89c6-7992548d98f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test data has 10000 samples\n",
            "every test data is 28 * 28 image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 구조 변경 -> 입력 레이어에 데이터 넣기 위함\n",
        "import numpy as np\n",
        "x_train = np.reshape(x_train, (60000,28,28,1))\n",
        "x_test = np.reshape(x_test, (10000,28,28,1))\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QfwTVMXqYH5",
        "outputId": "72037816-61e7-402f-c044-4467ca4ff18c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 정규화 -> 학습 시간 단축, 성능 높임\n",
        "#값을 0,1사이값으로 정규화\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "gray_scale = 255\n",
        "x_train /= gray_scale\n",
        "x_test /= gray_scale"
      ],
      "metadata": {
        "id": "1p_7gqe_qezx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#실제값을 one hot encoding으로 변경 -> 손실함수에서 크로스 엔트로피 계산\n",
        "num_classes = 10\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "swi0ML0Zqnhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN 텐서플로우 구현\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, kernel_size=(5, 5),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28,28,1),padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=2, restore_best_weights=False),\n",
        "             ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True)]\n",
        "\n",
        "# 코드 설명\n",
        "# 첫번째 CONV에는 16개 필터, 크기 5*5, 편향값은 필터 개수만큼, 활성화 함수로 relu사용\n",
        "# CONV레이어 다음으로 풀링 레이어로 액티베이션 맵 크기 줄임 -> 모델 크기 작아짐, 과대접합 위험도 감소\n",
        "# 풀링 레이어로 맵크기는 14*14가 됨, 다음으로 CONV2에 입력, 32개의 필터, 풀링 레이어 이후 액티베이션 맵 크기 7*7\n",
        "# FC는 CONV로 추출된 이미지 특징 입력받아 0-9숫자중 하나로 이미지 분류, flatten사용해 모든 특징들을 하나의 배열로 형변환, 형변환된 특징들은 FC에 입력\n",
        "# FC영역에는 총 2개의 dense 레이어 존재, 첫번째 레이어는 128개 노드, 두번째 레이어는 10개 노드(10개의 노드값을 softmax가 입력해 각 노드별 확률 구하기위해), 각 노드는 0-9의미, 이 예측값은 크로스 엔트로피를 통해 실제값과의 차이 게산\n",
        "# 크로스 엔트로피 + 아담 옵티마이저로 모델 최적화, 두번 이상 개선이 없으면 조기 종료"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug17w6zoqxb1",
        "outputId": "cce5b40a-aead-474e-a15c-f42c7d7cdf7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 16)        416       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 32)        12832     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1568)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               200832    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 215,370\n",
            "Trainable params: 215,370\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 시작&결과\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=500,\n",
        "          epochs=5,\n",
        "          verbose=1,\n",
        "          validation_split = 0.1, \n",
        "          callbacks=callbacks)\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ59TpOWq_X4",
        "outputId": "553aed7e-4f11-49c3-c9e4-24bc962fcb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "108/108 [==============================] - 13s 13ms/step - loss: 0.4869 - accuracy: 0.8703 - val_loss: 0.1218 - val_accuracy: 0.9657\n",
            "Epoch 2/5\n",
            "108/108 [==============================] - 1s 11ms/step - loss: 0.1076 - accuracy: 0.9681 - val_loss: 0.0773 - val_accuracy: 0.9783\n",
            "Epoch 3/5\n",
            "108/108 [==============================] - 1s 11ms/step - loss: 0.0713 - accuracy: 0.9785 - val_loss: 0.0573 - val_accuracy: 0.9845\n",
            "Epoch 4/5\n",
            "108/108 [==============================] - 1s 10ms/step - loss: 0.0542 - accuracy: 0.9837 - val_loss: 0.0480 - val_accuracy: 0.9872\n",
            "Epoch 5/5\n",
            "108/108 [==============================] - 1s 10ms/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.0415 - val_accuracy: 0.9890\n",
            "Test loss: 0.03843892365694046\n",
            "Test accuracy: 0.9865000247955322\n"
          ]
        }
      ]
    }
  ]
}