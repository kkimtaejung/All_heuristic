{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":["BzizH7CRocCk"],"authorship_tag":"ABX9TyNwCDBS87UJy9SEMeklBbtm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 자연어처리 모델 발전 과정"],"metadata":{"id":"BzizH7CRocCk"}},{"cell_type":"markdown","source":["## RNN"],"metadata":{"id":"VpmN1NdQwmaP"}},{"cell_type":"markdown","source":["- 연속적인 짧은 시퀀스 (자연어 처리, 음성인식, 주식, 날씨) 처리를 위해 등장\n","- 기존의 DNN (독립적인 파라미터들) 과 달리, RNN (파라미터 공유) 특징\n","- 하지만 시퀀스 길이가 길어지면 Gradient Vanishing 문제"],"metadata":{"id":"C32ODXwnws93"}},{"cell_type":"markdown","source":["## LSTM"],"metadata":{"id":"xqHdO1MXwyks"}},{"cell_type":"markdown","source":["- RNN의 문제점, 뒤로갈수록 처음의 입력 정보가 사라진다\n","- 핵심 입력 정보를 뒤로 전달하기 위한 Cell state 구조를 생성\n","- Gate\n","  - 입력 게이트\n","  - 망각 게이트\n","  - 출력 게이트\n","  - 업데이트 게이트"],"metadata":{"id":"2T0RuAM_xCsQ"}},{"cell_type":"markdown","source":["## GRU (Gated Recrurent Unit)"],"metadata":{"id":"EEtGYRbA2qlN"}},{"cell_type":"markdown","source":["- LSTM보다 매개변수가 적은 LSTM 변형 모델\n","- 소규모 데이터셋에 좋은 성능\n","- Gate\n","  - 업데이트 게이트\n","  - 리셋 게이트"],"metadata":{"id":"oh14BNmN2vRK"}},{"cell_type":"markdown","source":["## Seq2Seq"],"metadata":{"id":"sVyjomv9xAqN"}},{"cell_type":"markdown","source":["- 인코더, 디코더의  두 개의 LSTM 구조\n","- 인코더로 입력 문장 처리\n","- 디코더로 답변 문장 처리"],"metadata":{"id":"oK1GxY5uxFGF"}},{"cell_type":"markdown","source":["## Attention"],"metadata":{"id":"8RPQ8_DJxY35"}},{"cell_type":"markdown","source":["- LSTM, Seq2Seq 문제점, 입력 문장의 길이가 늘어나면 정확도가 떨어짐\n","- 중요한 단어에 집중하여 디코더에 바로 전달"],"metadata":{"id":"OpykYxq2xbrB"}},{"cell_type":"markdown","source":["## Transformer"],"metadata":{"id":"SFPMxZr9xsUJ"}},{"cell_type":"markdown","source":["- 2017 Google\n","- Attention 만으로 인코더-디코더 구현 (LSTM X)\n","- 스스로 언어에 집중을 한다는 특징"],"metadata":{"id":"AZBHtWbAxuvh"}},{"cell_type":"markdown","source":["## BERT (Bidirectional Encoder Representations from Transformers)"],"metadata":{"id":"Gl9pWrVmyDh6"}},{"cell_type":"markdown","source":["- 2018 Google\n","- 사전 훈련 기반 딥러닝 언어모델 (새로운 모델을 만들어 다시 학습, 전이 학습)\n","- 요약 ㅡ 언어를 배운 후에 부가적인 것을 배우는것이 훨씩 효율적\n","- 그 외\n","  - ELMo"],"metadata":{"id":"kt9iakLjyG6N"}}]}